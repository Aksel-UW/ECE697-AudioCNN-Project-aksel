{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU6ICpDBu56p"
      },
      "outputs": [],
      "source": [
        "TRIAL_NUMBER = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOAPNWAP_KV6",
        "outputId": "8a4e772e-79aa-4b5c-d01d-37b7ceced204"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qe2o0qf_Qto"
      },
      "outputs": [],
      "source": [
        "#### https://www.youtube.com/watch?v=SQ1iIKs190Q&list=PL-wATfeyAMNoirN4idjev6aRu8ISZYVWm&index=8\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN4piFqE_TSA",
        "outputId": "6467d607-82ff-468a-c65e-25c0165285fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zYMCs7L_T4o"
      },
      "outputs": [],
      "source": [
        "!tar -xf /content/drive/MyDrive/UrbanSound8K.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF8zTkG09NfE"
      },
      "outputs": [],
      "source": [
        "#### defining filters\n",
        "\n",
        "## https://www.youtube.com/watch?v=L5RshXUwdFA\n",
        "\n",
        "class myFilter(nn.Module):\n",
        "    def __init__(self, sampling_rate = 22050):\n",
        "        super().__init__()\n",
        "        self.sampling_rate = sampling_rate\n",
        "\n",
        "        gamma_scale = torch.Tensor(1,device = 'cpu')\n",
        "        self.gamma_scale = nn.Parameter(gamma_scale)\n",
        "\n",
        "        sharpness_scale = torch.Tensor(1,device = 'cpu')\n",
        "        self.sharpness_scale = nn.Parameter(sharpness_scale)\n",
        "        \n",
        "    def forward(self, filter_parameters: torch.Tensor, input: torch.Tensor):\n",
        "        self.gamma_scale = nn.Parameter(filter_parameters[0][0])\n",
        "        self.sharpness_scale = nn.Parameter(filter_parameters[0][1])\n",
        "\n",
        "        filtered_signal = input\n",
        "        \n",
        "        filtered_signal = torchvision.transforms.functional.adjust_gamma(\n",
        "                              filtered_signal, \n",
        "                              gamma = self.gamma_scale.clamp(min=0.01))\n",
        "\n",
        "        filtered_signal = torchvision.transforms.functional.adjust_sharpness(\n",
        "                              filtered_signal ,\n",
        "                              sharpness_factor = self.sharpness_scale.clamp(min=1))\n",
        "        return filtered_signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru6kkUlj_ZpR",
        "outputId": "020899eb-07b9-43b4-ae80-dd6fbd34abd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "CNN_Filter_Network                       [1, 10]                   --\n",
            "├─Sequential: 1-1                        [1, 16, 16, 11]           --\n",
            "│    └─Conv2d: 2-1                       [1, 16, 33, 23]           160\n",
            "│    └─LeakyReLU: 2-2                    [1, 16, 33, 23]           --\n",
            "│    └─MaxPool2d: 2-3                    [1, 16, 16, 11]           --\n",
            "├─Sequential: 1-2                        [1, 32, 4, 3]             --\n",
            "│    └─Conv2d: 2-4                       [1, 32, 9, 7]             4,640\n",
            "│    └─LeakyReLU: 2-5                    [1, 32, 9, 7]             --\n",
            "│    └─MaxPool2d: 2-6                    [1, 32, 4, 3]             --\n",
            "├─Sequential: 1-3                        [1, 32, 1, 1]             --\n",
            "│    └─Conv2d: 2-7                       [1, 32, 3, 3]             9,248\n",
            "│    └─LeakyReLU: 2-8                    [1, 32, 3, 3]             --\n",
            "│    └─MaxPool2d: 2-9                    [1, 32, 1, 1]             --\n",
            "├─Sequential: 1-4                        [1, 32, 1, 1]             --\n",
            "│    └─Conv2d: 2-10                      [1, 32, 2, 2]             9,248\n",
            "│    └─LeakyReLU: 2-11                   [1, 32, 2, 2]             --\n",
            "│    └─MaxPool2d: 2-12                   [1, 32, 1, 1]             --\n",
            "├─Sequential: 1-5                        [1, 32, 1, 1]             --\n",
            "│    └─Conv2d: 2-13                      [1, 32, 2, 2]             9,248\n",
            "│    └─LeakyReLU: 2-14                   [1, 32, 2, 2]             --\n",
            "│    └─MaxPool2d: 2-15                   [1, 32, 1, 1]             --\n",
            "├─Flatten: 1-6                           [1, 32]                   --\n",
            "├─Linear: 1-7                            [1, 20]                   660\n",
            "├─Linear: 1-8                            [1, 2]                    42\n",
            "├─myFilter: 1-9                          [1, 1, 64, 44]            2\n",
            "├─Sequential: 1-10                       [1, 16, 33, 23]           --\n",
            "│    └─Conv2d: 2-16                      [1, 16, 66, 46]           160\n",
            "│    └─LeakyReLU: 2-17                   [1, 16, 66, 46]           --\n",
            "│    └─MaxPool2d: 2-18                   [1, 16, 33, 23]           --\n",
            "├─Sequential: 1-11                       [1, 32, 17, 12]           --\n",
            "│    └─Conv2d: 2-19                      [1, 32, 35, 25]           4,640\n",
            "│    └─LeakyReLU: 2-20                   [1, 32, 35, 25]           --\n",
            "│    └─MaxPool2d: 2-21                   [1, 32, 17, 12]           --\n",
            "├─Sequential: 1-12                       [1, 32, 9, 7]             --\n",
            "│    └─Conv2d: 2-22                      [1, 32, 19, 14]           9,248\n",
            "│    └─LeakyReLU: 2-23                   [1, 32, 19, 14]           --\n",
            "│    └─MaxPool2d: 2-24                   [1, 32, 9, 7]             --\n",
            "├─Sequential: 1-13                       [1, 64, 5, 4]             --\n",
            "│    └─Conv2d: 2-25                      [1, 64, 11, 9]            18,496\n",
            "│    └─LeakyReLU: 2-26                   [1, 64, 11, 9]            --\n",
            "│    └─MaxPool2d: 2-27                   [1, 64, 5, 4]             --\n",
            "├─Sequential: 1-14                       [1, 64, 3, 3]             --\n",
            "│    └─Conv2d: 2-28                      [1, 64, 7, 6]             36,928\n",
            "│    └─LeakyReLU: 2-29                   [1, 64, 7, 6]             --\n",
            "│    └─MaxPool2d: 2-30                   [1, 64, 3, 3]             --\n",
            "├─Flatten: 1-15                          [1, 576]                  --\n",
            "├─Linear: 1-16                           [1, 32]                   18,464\n",
            "├─Linear: 1-17                           [1, 10]                   330\n",
            "├─Softmax: 1-18                          [1, 10]                   --\n",
            "==========================================================================================\n",
            "Total params: 121,514\n",
            "Trainable params: 121,514\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 10.98\n",
            "==========================================================================================\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.89\n",
            "Params size (MB): 0.49\n",
            "Estimated Total Size (MB): 1.39\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "class CNN_Filter_Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # 5 conv blocks / flatten / linear / softmax\n",
        "        self.filtconv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 1,\n",
        "                out_channels = 16,\n",
        "                kernel_size = 3,\n",
        "                stride = 2,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.filtconv2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 16,\n",
        "                out_channels = 32,\n",
        "                kernel_size = 3,\n",
        "                stride = 2,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.filtconv3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 32,\n",
        "                out_channels = 32,\n",
        "                kernel_size = 3,\n",
        "                stride = 2,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.filtconv4 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 32,\n",
        "                out_channels = 32,\n",
        "                kernel_size = 3,\n",
        "                stride = 2,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.filtconv5 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 32,\n",
        "                out_channels = 32,\n",
        "                kernel_size = 3,\n",
        "                stride = 2,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.filtflatten = nn.Flatten()\n",
        "        self.filtfc1 = nn.Linear(32, 20)\n",
        "        self.filtfc2 = nn.Linear(20, 2)\n",
        "        self.filter1 = myFilter()\n",
        "\n",
        "        ########### END OF FILTER ##############\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 1,\n",
        "                out_channels = 16,\n",
        "                kernel_size = 3,\n",
        "                stride = 1,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 16,\n",
        "                out_channels = 32,\n",
        "                kernel_size = 3,\n",
        "                stride = 1,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 32,\n",
        "                out_channels = 32,\n",
        "                kernel_size = 3,\n",
        "                stride = 1,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 32,\n",
        "                out_channels = 64,\n",
        "                kernel_size = 3,\n",
        "                stride = 1,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels = 64,\n",
        "                out_channels = 64,\n",
        "                kernel_size = 3,\n",
        "                stride = 1,\n",
        "                padding = 2\n",
        "            ),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)     \n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(576, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "        \n",
        "    def forward(self, input_data):\n",
        "        filt_params = self.filtconv1(input_data)\n",
        "        filt_params = self.filtconv2(filt_params)\n",
        "        filt_params = self.filtconv3(filt_params)\n",
        "        filt_params = self.filtconv4(filt_params)\n",
        "        filt_params = self.filtconv5(filt_params)\n",
        "        filt_params = self.filtflatten(filt_params)\n",
        "        filt_params = self.filtfc1(filt_params)\n",
        "        filt_params = self.filtfc2(filt_params)\n",
        "        x = self.filter1(filt_params,input_data)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        logits = self.fc2(x)\n",
        "        predictions = self.softmax(logits)\n",
        "        return predictions\n",
        "        \n",
        "        \n",
        "if __name__ == \"__main__\":\n",
        "    cnn = CNN_Filter_Network()\n",
        "    print(summary(cnn, (1,1, 64, 44), device = 'cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF5gNKiC_hSn",
        "outputId": "7cef64a0-121b-4fdb-db77-928bd6ba6b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device cuda\n",
            "There are 8732 samples in the dataset.\n",
            "sox_io\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import soundfile\n",
        "import torchaudio\n",
        "\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 annotations_file,\n",
        "                 audio_dir,\n",
        "                 transformation,\n",
        "                 target_sample_rate,\n",
        "                 num_samples,\n",
        "                 device):\n",
        "        self.annotations = pd.read_csv(annotations_file)\n",
        "        self.audio_dir = audio_dir\n",
        "        self.device = device\n",
        "        self.transformation = transformation.to(self.device)\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        audio_sample_path = self._get_audio_sample_path(index)\n",
        "        label = self._get_audio_sample_label(index)\n",
        "        signal, sr = torchaudio.load(audio_sample_path)\n",
        "        signal = signal.to(self.device)\n",
        "        signal = self._resample_if_necessary(signal, sr)\n",
        "        signal = self._mix_down_if_necessary(signal)\n",
        "        signal = self._cut_if_necessary(signal)\n",
        "        signal = self._right_pad_if_necessary(signal)\n",
        "        signal = self.transformation(signal)\n",
        "        signal = signal/signal.max() # normalize 0 to 1\n",
        "        #signal = (signal - signal.mean())/signal.std() # normalize\n",
        "        return signal, label\n",
        "\n",
        "    def _cut_if_necessary(self, signal):\n",
        "        if signal.shape[1] > self.num_samples:\n",
        "            signal = signal[:, :self.num_samples]\n",
        "        return signal\n",
        "\n",
        "    def _right_pad_if_necessary(self, signal):\n",
        "        length_signal = signal.shape[1]\n",
        "        if length_signal < self.num_samples:\n",
        "            num_missing_samples = self.num_samples - length_signal\n",
        "            last_dim_padding = (0, num_missing_samples)\n",
        "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
        "        return signal\n",
        "\n",
        "    def _resample_if_necessary(self, signal, sr):\n",
        "        if sr != self.target_sample_rate:\n",
        "\n",
        "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).cuda()\n",
        "\n",
        "            signal = resampler(signal)\n",
        "        return signal\n",
        "\n",
        "    def _mix_down_if_necessary(self, signal):\n",
        "        if signal.shape[0] > 1:\n",
        "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
        "        return signal\n",
        "\n",
        "    def _get_audio_sample_path(self, index):\n",
        "        fold = f\"fold{self.annotations.iloc[index, 5]}\"\n",
        "        path = os.path.join(self.audio_dir, fold, self.annotations.iloc[\n",
        "            index, 0])\n",
        "        return path\n",
        "\n",
        "    def _get_audio_sample_label(self, index):\n",
        "        return self.annotations.iloc[index, 6]\n",
        "\n",
        "\n",
        "ANNOTATIONS_FILE = \"/content/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
        "AUDIO_DIR = \"/content/UrbanSound8K/audio\"\n",
        "SAMPLE_RATE = 22050\n",
        "NUM_SAMPLES = 22050\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "print(f\"Using device {device}\")\n",
        "\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=SAMPLE_RATE,\n",
        "    n_fft=1024,\n",
        "    hop_length=512,\n",
        "    n_mels=64\n",
        ")\n",
        "\n",
        "usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n",
        "                        AUDIO_DIR,\n",
        "                        mel_spectrogram,\n",
        "                        SAMPLE_RATE,\n",
        "                        NUM_SAMPLES,\n",
        "                        device)\n",
        "print(f\"There are {len(usd)} samples in the dataset.\")\n",
        "print(str(torchaudio.get_audio_backend()))\n",
        "signal, label = usd[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XBfVXt4_isf"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\"):\n",
        "    fig, axs = plt.subplots(1, 1)\n",
        "    axs.set_title(title or \"Spectrogram (db)\")\n",
        "    axs.set_ylabel(ylabel)\n",
        "    axs.set_xlabel(\"frame\")\n",
        "    im = axs.imshow(librosa.power_to_db(specgram), origin=\"lower\", aspect=\"auto\")\n",
        "    fig.colorbar(im, ax=axs)\n",
        "    plt.show(block=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqx2uldvvAE_",
        "outputId": "f559ff2f-a32e-475d-8df7-aba6cef8305b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f505f1ee970>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(TRIAL_NUMBER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbsvQJaqAZge"
      },
      "outputs": [],
      "source": [
        "train_set, test_set = torch.utils.data.random_split(usd, [7732, 1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LGA889yo_ozX",
        "outputId": "7b1b752d-517c-49f7-e2e1-38d0315239a8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_spectrogram(train_set[2222][0].to(\"cpu\")[0], title=\"torchaudio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoxabJYojMIb",
        "outputId": "e767deb3-659d-4579-a4b0-bd7cacccfa7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda\n",
            "CNN_Filter_Network(\n",
            "  (filtconv1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (filtconv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (filtconv3): Sequential(\n",
            "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (filtconv4): Sequential(\n",
            "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (filtconv5): Sequential(\n",
            "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (filtflatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (filtfc1): Linear(in_features=32, out_features=20, bias=True)\n",
            "  (filtfc2): Linear(in_features=20, out_features=2, bias=True)\n",
            "  (filter1): myFilter()\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=576, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Epoch 1\n",
            "loss: 2.294862985610962\n",
            "---------------------------\n",
            "Epoch 2\n",
            "loss: 2.294487237930298\n",
            "---------------------------\n",
            "Epoch 3\n",
            "loss: 2.2928199768066406\n",
            "---------------------------\n",
            "Epoch 4\n",
            "loss: 2.2915027141571045\n",
            "---------------------------\n",
            "Epoch 5\n",
            "loss: 2.2883028984069824\n",
            "---------------------------\n",
            "Epoch 6\n",
            "loss: 2.286600351333618\n",
            "---------------------------\n",
            "Epoch 7\n",
            "loss: 2.272369384765625\n",
            "---------------------------\n",
            "Epoch 8\n",
            "loss: 2.2771644592285156\n",
            "---------------------------\n",
            "Epoch 9\n",
            "loss: 2.2717435359954834\n",
            "---------------------------\n",
            "Epoch 10\n",
            "loss: 2.271946668624878\n",
            "---------------------------\n",
            "Epoch 11\n",
            "loss: 2.269566059112549\n",
            "---------------------------\n",
            "Epoch 12\n",
            "loss: 2.257132053375244\n",
            "---------------------------\n",
            "Epoch 13\n",
            "loss: 2.2330257892608643\n",
            "---------------------------\n",
            "Epoch 14\n",
            "loss: 2.2826836109161377\n",
            "---------------------------\n",
            "Epoch 15\n",
            "loss: 2.270920515060425\n",
            "---------------------------\n",
            "Epoch 16\n",
            "loss: 2.2549562454223633\n",
            "---------------------------\n",
            "Epoch 17\n",
            "loss: 2.2678122520446777\n",
            "---------------------------\n",
            "Epoch 18\n",
            "loss: 2.219872236251831\n",
            "---------------------------\n",
            "Epoch 19\n",
            "loss: 2.2317864894866943\n",
            "---------------------------\n",
            "Epoch 20\n",
            "loss: 2.1997623443603516\n",
            "---------------------------\n",
            "Epoch 21\n",
            "loss: 2.1744863986968994\n",
            "---------------------------\n",
            "Epoch 22\n",
            "loss: 2.1676785945892334\n",
            "---------------------------\n",
            "Epoch 23\n",
            "loss: 2.143155336380005\n",
            "---------------------------\n",
            "Epoch 24\n",
            "loss: 2.160038471221924\n",
            "---------------------------\n",
            "Epoch 25\n",
            "loss: 2.1431398391723633\n",
            "---------------------------\n",
            "Epoch 26\n",
            "loss: 2.169936180114746\n",
            "---------------------------\n",
            "Epoch 27\n",
            "loss: 2.1544511318206787\n",
            "---------------------------\n",
            "Epoch 28\n",
            "loss: 2.1476032733917236\n",
            "---------------------------\n",
            "Epoch 29\n",
            "loss: 2.1648449897766113\n",
            "---------------------------\n",
            "Epoch 30\n",
            "loss: 2.1324281692504883\n",
            "---------------------------\n",
            "Epoch 31\n",
            "loss: 2.1207222938537598\n",
            "---------------------------\n",
            "Epoch 32\n",
            "loss: 2.117429733276367\n",
            "---------------------------\n",
            "Epoch 33\n",
            "loss: 2.101552963256836\n",
            "---------------------------\n",
            "Epoch 34\n",
            "loss: 2.1062867641448975\n",
            "---------------------------\n",
            "Epoch 35\n",
            "loss: 2.0964205265045166\n",
            "---------------------------\n",
            "Epoch 36\n",
            "loss: 2.081470012664795\n",
            "---------------------------\n",
            "Epoch 37\n",
            "loss: 2.0775232315063477\n",
            "---------------------------\n",
            "Epoch 38\n",
            "loss: 2.0663602352142334\n",
            "---------------------------\n",
            "Epoch 39\n",
            "loss: 2.057966709136963\n",
            "---------------------------\n",
            "Epoch 40\n",
            "loss: 2.05387544631958\n",
            "---------------------------\n",
            "Epoch 41\n",
            "loss: 2.0521814823150635\n",
            "---------------------------\n",
            "Epoch 42\n",
            "loss: 2.0385825634002686\n",
            "---------------------------\n",
            "Epoch 43\n",
            "loss: 2.033050537109375\n",
            "---------------------------\n",
            "Epoch 44\n",
            "loss: 2.0394082069396973\n",
            "---------------------------\n",
            "Epoch 45\n",
            "loss: 2.022549629211426\n",
            "---------------------------\n",
            "Epoch 46\n",
            "loss: 2.025717258453369\n",
            "---------------------------\n",
            "Epoch 47\n",
            "loss: 2.0229432582855225\n",
            "---------------------------\n",
            "Epoch 48\n",
            "loss: 2.0971782207489014\n",
            "---------------------------\n",
            "Epoch 49\n",
            "loss: 2.0461840629577637\n",
            "---------------------------\n",
            "Epoch 50\n",
            "loss: 2.068214178085327\n",
            "---------------------------\n",
            "Epoch 51\n",
            "loss: 2.055851936340332\n",
            "---------------------------\n",
            "Epoch 52\n",
            "loss: 2.0221798419952393\n",
            "---------------------------\n",
            "Epoch 53\n",
            "loss: 2.0393030643463135\n",
            "---------------------------\n",
            "Epoch 54\n",
            "loss: 2.0673601627349854\n",
            "---------------------------\n",
            "Epoch 55\n",
            "loss: 2.04657244682312\n",
            "---------------------------\n",
            "Epoch 56\n",
            "loss: 2.066587448120117\n",
            "---------------------------\n",
            "Epoch 57\n",
            "loss: 2.0305044651031494\n",
            "---------------------------\n",
            "Epoch 58\n",
            "loss: 2.0244646072387695\n",
            "---------------------------\n",
            "Epoch 59\n",
            "loss: 2.0069236755371094\n",
            "---------------------------\n",
            "Epoch 60\n",
            "loss: 2.0466678142547607\n",
            "---------------------------\n",
            "Epoch 61\n",
            "loss: 2.0017142295837402\n",
            "---------------------------\n",
            "Epoch 62\n",
            "loss: 2.0369997024536133\n",
            "---------------------------\n",
            "Epoch 63\n",
            "loss: 2.05135178565979\n",
            "---------------------------\n",
            "Epoch 64\n",
            "loss: 2.010699510574341\n",
            "---------------------------\n",
            "Epoch 65\n",
            "loss: 2.02051043510437\n",
            "---------------------------\n",
            "Epoch 66\n",
            "loss: 1.9999994039535522\n",
            "---------------------------\n",
            "Epoch 67\n",
            "loss: 1.996788740158081\n",
            "---------------------------\n",
            "Epoch 68\n",
            "loss: 2.0071887969970703\n",
            "---------------------------\n",
            "Epoch 69\n",
            "loss: 2.033947229385376\n",
            "---------------------------\n",
            "Epoch 70\n",
            "loss: 2.0077035427093506\n",
            "---------------------------\n",
            "Epoch 71\n",
            "loss: 2.053668975830078\n",
            "---------------------------\n",
            "Epoch 72\n",
            "loss: 2.0271503925323486\n",
            "---------------------------\n",
            "Epoch 73\n",
            "loss: 2.0267975330352783\n",
            "---------------------------\n",
            "Epoch 74\n",
            "loss: 2.0136542320251465\n",
            "---------------------------\n",
            "Epoch 75\n",
            "loss: 2.0097389221191406\n",
            "---------------------------\n",
            "Epoch 76\n",
            "loss: 1.99770188331604\n",
            "---------------------------\n",
            "Epoch 77\n",
            "loss: 2.0038886070251465\n",
            "---------------------------\n",
            "Epoch 78\n",
            "loss: 2.0086328983306885\n",
            "---------------------------\n",
            "Epoch 79\n",
            "loss: 2.0333807468414307\n",
            "---------------------------\n",
            "Epoch 80\n",
            "loss: 2.0031256675720215\n",
            "---------------------------\n",
            "Epoch 81\n",
            "loss: 1.9884905815124512\n",
            "---------------------------\n",
            "Epoch 82\n",
            "loss: 1.9851429462432861\n",
            "---------------------------\n",
            "Epoch 83\n",
            "loss: 1.983181357383728\n",
            "---------------------------\n",
            "Epoch 84\n",
            "loss: 1.9865058660507202\n",
            "---------------------------\n",
            "Epoch 85\n",
            "loss: 1.9743973016738892\n",
            "---------------------------\n",
            "Epoch 86\n",
            "loss: 1.9757156372070312\n",
            "---------------------------\n",
            "Epoch 87\n",
            "loss: 1.990484356880188\n",
            "---------------------------\n",
            "Epoch 88\n",
            "loss: 1.969160795211792\n",
            "---------------------------\n",
            "Epoch 89\n",
            "loss: 1.979459285736084\n",
            "---------------------------\n",
            "Epoch 90\n",
            "loss: 1.9723683595657349\n",
            "---------------------------\n",
            "Epoch 91\n",
            "loss: 1.9700123071670532\n",
            "---------------------------\n",
            "Epoch 92\n",
            "loss: 1.9658458232879639\n",
            "---------------------------\n",
            "Epoch 93\n",
            "loss: 1.972070574760437\n",
            "---------------------------\n",
            "Epoch 94\n",
            "loss: 2.007603168487549\n",
            "---------------------------\n",
            "Epoch 95\n",
            "loss: 1.9786924123764038\n",
            "---------------------------\n",
            "Epoch 96\n",
            "loss: 1.965093970298767\n",
            "---------------------------\n",
            "Epoch 97\n",
            "loss: 1.9624559879302979\n",
            "---------------------------\n",
            "Epoch 98\n",
            "loss: 1.963889718055725\n",
            "---------------------------\n",
            "Epoch 99\n",
            "loss: 1.95830237865448\n",
            "---------------------------\n",
            "Epoch 100\n",
            "loss: 1.9576283693313599\n",
            "---------------------------\n",
            "Epoch 101\n",
            "loss: 1.9598942995071411\n",
            "---------------------------\n",
            "Epoch 102\n",
            "loss: 1.963963270187378\n",
            "---------------------------\n",
            "Epoch 103\n",
            "loss: 1.9605882167816162\n",
            "---------------------------\n",
            "Epoch 104\n",
            "loss: 1.988093376159668\n",
            "---------------------------\n",
            "Epoch 105\n",
            "loss: 1.962127685546875\n",
            "---------------------------\n",
            "Epoch 106\n",
            "loss: 1.9518567323684692\n",
            "---------------------------\n",
            "Epoch 107\n",
            "loss: 1.9538533687591553\n",
            "---------------------------\n",
            "Epoch 108\n",
            "loss: 1.9536879062652588\n",
            "---------------------------\n",
            "Epoch 109\n",
            "loss: 1.9464867115020752\n",
            "---------------------------\n",
            "Epoch 110\n",
            "loss: 1.9691143035888672\n",
            "---------------------------\n",
            "Epoch 111\n",
            "loss: 1.957585096359253\n",
            "---------------------------\n",
            "Epoch 112\n",
            "loss: 1.9469187259674072\n",
            "---------------------------\n",
            "Epoch 113\n",
            "loss: 2.0257928371429443\n",
            "---------------------------\n",
            "Epoch 114\n",
            "loss: 1.9663631916046143\n",
            "---------------------------\n",
            "Epoch 115\n",
            "loss: 1.9536068439483643\n",
            "---------------------------\n",
            "Epoch 116\n",
            "loss: 1.9509800672531128\n",
            "---------------------------\n",
            "Epoch 117\n",
            "loss: 1.975280523300171\n",
            "---------------------------\n",
            "Epoch 118\n",
            "loss: 1.985815405845642\n",
            "---------------------------\n",
            "Epoch 119\n",
            "loss: 1.950333833694458\n",
            "---------------------------\n",
            "Epoch 120\n",
            "loss: 1.969700574874878\n",
            "---------------------------\n",
            "Epoch 121\n",
            "loss: 1.9952470064163208\n",
            "---------------------------\n",
            "Epoch 122\n",
            "loss: 1.949317455291748\n",
            "---------------------------\n",
            "Epoch 123\n",
            "loss: 1.934827208518982\n",
            "---------------------------\n",
            "Epoch 124\n",
            "loss: 1.939896821975708\n",
            "---------------------------\n",
            "Epoch 125\n",
            "loss: 1.9334816932678223\n",
            "---------------------------\n",
            "Epoch 126\n",
            "loss: 1.9371592998504639\n",
            "---------------------------\n",
            "Epoch 127\n",
            "loss: 1.937944769859314\n",
            "---------------------------\n",
            "Epoch 128\n",
            "loss: 1.934462308883667\n",
            "---------------------------\n",
            "Epoch 129\n",
            "loss: 1.9638749361038208\n",
            "---------------------------\n",
            "Epoch 130\n",
            "loss: 1.9414983987808228\n",
            "---------------------------\n",
            "Epoch 131\n",
            "loss: 1.9615346193313599\n",
            "---------------------------\n",
            "Epoch 132\n",
            "loss: 1.9540750980377197\n",
            "---------------------------\n",
            "Epoch 133\n",
            "loss: 1.9454820156097412\n",
            "---------------------------\n",
            "Epoch 134\n",
            "loss: 1.9597396850585938\n",
            "---------------------------\n",
            "Epoch 135\n",
            "loss: 1.964493989944458\n",
            "---------------------------\n",
            "Epoch 136\n",
            "loss: 1.9413096904754639\n",
            "---------------------------\n",
            "Epoch 137\n",
            "loss: 1.9290485382080078\n",
            "---------------------------\n",
            "Epoch 138\n",
            "loss: 1.9509049654006958\n",
            "---------------------------\n",
            "Epoch 139\n",
            "loss: 1.939449667930603\n",
            "---------------------------\n",
            "Epoch 140\n",
            "loss: 1.9280871152877808\n",
            "---------------------------\n",
            "Epoch 141\n",
            "loss: 1.9233238697052002\n",
            "---------------------------\n",
            "Epoch 142\n",
            "loss: 1.915395975112915\n",
            "---------------------------\n",
            "Epoch 143\n",
            "loss: 1.9120078086853027\n",
            "---------------------------\n",
            "Epoch 144\n",
            "loss: 1.9117062091827393\n",
            "---------------------------\n",
            "Epoch 145\n",
            "loss: 1.908486008644104\n",
            "---------------------------\n",
            "Epoch 146\n",
            "loss: 1.925111174583435\n",
            "---------------------------\n",
            "Epoch 147\n",
            "loss: 1.910631537437439\n",
            "---------------------------\n",
            "Epoch 148\n",
            "loss: 1.9214626550674438\n",
            "---------------------------\n",
            "Epoch 149\n",
            "loss: 1.9185702800750732\n",
            "---------------------------\n",
            "Epoch 150\n",
            "loss: 1.934088110923767\n",
            "---------------------------\n",
            "Epoch 151\n",
            "loss: 1.9105839729309082\n",
            "---------------------------\n",
            "Epoch 152\n",
            "loss: 1.9183365106582642\n",
            "---------------------------\n",
            "Epoch 153\n",
            "loss: 1.929486632347107\n",
            "---------------------------\n",
            "Epoch 154\n",
            "loss: 1.952204942703247\n",
            "---------------------------\n",
            "Epoch 155\n",
            "loss: 1.9221693277359009\n",
            "---------------------------\n",
            "Epoch 156\n",
            "loss: 1.9299297332763672\n",
            "---------------------------\n",
            "Epoch 157\n",
            "loss: 1.917488694190979\n",
            "---------------------------\n",
            "Epoch 158\n",
            "loss: 1.946254849433899\n",
            "---------------------------\n",
            "Epoch 159\n",
            "loss: 1.918282389640808\n",
            "---------------------------\n",
            "Epoch 160\n",
            "loss: 1.9141241312026978\n",
            "---------------------------\n",
            "Epoch 161\n",
            "loss: 1.902911901473999\n",
            "---------------------------\n",
            "Epoch 162\n",
            "loss: 1.9029066562652588\n",
            "---------------------------\n",
            "Epoch 163\n",
            "loss: 1.896561861038208\n",
            "---------------------------\n",
            "Epoch 164\n",
            "loss: 1.894828200340271\n",
            "---------------------------\n",
            "Epoch 165\n",
            "loss: 1.8940694332122803\n",
            "---------------------------\n",
            "Epoch 166\n",
            "loss: 1.894775629043579\n",
            "---------------------------\n",
            "Epoch 167\n",
            "loss: 1.917818307876587\n",
            "---------------------------\n",
            "Epoch 168\n",
            "loss: 1.9082578420639038\n",
            "---------------------------\n",
            "Epoch 169\n",
            "loss: 1.893818974494934\n",
            "---------------------------\n",
            "Epoch 170\n",
            "loss: 1.9033548831939697\n",
            "---------------------------\n",
            "Epoch 171\n",
            "loss: 1.9151781797409058\n",
            "---------------------------\n",
            "Epoch 172\n",
            "loss: 1.898169994354248\n",
            "---------------------------\n",
            "Epoch 173\n",
            "loss: 1.904802918434143\n",
            "---------------------------\n",
            "Epoch 174\n",
            "loss: 1.944637656211853\n",
            "---------------------------\n",
            "Epoch 175\n",
            "loss: 1.946419596672058\n",
            "---------------------------\n",
            "Epoch 176\n",
            "loss: 1.919669508934021\n",
            "---------------------------\n",
            "Epoch 177\n",
            "loss: 1.9223459959030151\n",
            "---------------------------\n",
            "Epoch 178\n",
            "loss: 1.9102859497070312\n",
            "---------------------------\n",
            "Epoch 179\n",
            "loss: 1.8901540040969849\n",
            "---------------------------\n",
            "Epoch 180\n",
            "loss: 1.895258903503418\n",
            "---------------------------\n",
            "Epoch 181\n",
            "loss: 1.9112378358840942\n",
            "---------------------------\n",
            "Epoch 182\n",
            "loss: 1.913859486579895\n",
            "---------------------------\n",
            "Epoch 183\n",
            "loss: 1.9007104635238647\n",
            "---------------------------\n",
            "Epoch 184\n",
            "loss: 1.9092600345611572\n",
            "---------------------------\n",
            "Epoch 185\n",
            "loss: 1.888994574546814\n",
            "---------------------------\n",
            "Epoch 186\n",
            "loss: 1.8985227346420288\n",
            "---------------------------\n",
            "Epoch 187\n",
            "loss: 1.8970880508422852\n",
            "---------------------------\n",
            "Epoch 188\n",
            "loss: 1.916642189025879\n",
            "---------------------------\n",
            "Epoch 189\n",
            "loss: 1.9248970746994019\n",
            "---------------------------\n",
            "Epoch 190\n",
            "loss: 1.8902077674865723\n",
            "---------------------------\n",
            "Epoch 191\n",
            "loss: 1.8956372737884521\n",
            "---------------------------\n",
            "Epoch 192\n",
            "loss: 1.892554521560669\n",
            "---------------------------\n",
            "Epoch 193\n",
            "loss: 1.8822088241577148\n",
            "---------------------------\n",
            "Epoch 194\n",
            "loss: 1.9010320901870728\n",
            "---------------------------\n",
            "Epoch 195\n",
            "loss: 1.8846796751022339\n",
            "---------------------------\n",
            "Epoch 196\n",
            "loss: 1.8759009838104248\n",
            "---------------------------\n",
            "Epoch 197\n",
            "loss: 1.8849340677261353\n",
            "---------------------------\n",
            "Epoch 198\n",
            "loss: 1.8878133296966553\n",
            "---------------------------\n",
            "Epoch 199\n",
            "loss: 1.888840913772583\n",
            "---------------------------\n",
            "Epoch 200\n",
            "loss: 1.9349561929702759\n",
            "---------------------------\n",
            "Epoch 201\n",
            "loss: 1.929008960723877\n",
            "---------------------------\n",
            "Epoch 202\n",
            "loss: 1.9001058340072632\n",
            "---------------------------\n",
            "Epoch 203\n",
            "loss: 1.905027985572815\n",
            "---------------------------\n",
            "Epoch 204\n",
            "loss: 1.888143539428711\n",
            "---------------------------\n",
            "Epoch 205\n",
            "loss: 1.8758748769760132\n",
            "---------------------------\n",
            "Epoch 206\n",
            "loss: 1.872774600982666\n",
            "---------------------------\n",
            "Epoch 207\n",
            "loss: 1.8795967102050781\n",
            "---------------------------\n",
            "Epoch 208\n",
            "loss: 1.8901245594024658\n",
            "---------------------------\n",
            "Epoch 209\n",
            "loss: 1.9006493091583252\n",
            "---------------------------\n",
            "Epoch 210\n",
            "loss: 1.8855558633804321\n",
            "---------------------------\n",
            "Epoch 211\n",
            "loss: 1.8861689567565918\n",
            "---------------------------\n",
            "Epoch 212\n",
            "loss: 1.8823637962341309\n",
            "---------------------------\n",
            "Epoch 213\n",
            "loss: 1.8834525346755981\n",
            "---------------------------\n",
            "Epoch 214\n",
            "loss: 1.8914238214492798\n",
            "---------------------------\n",
            "Epoch 215\n",
            "loss: 1.857837438583374\n",
            "---------------------------\n",
            "Epoch 216\n",
            "loss: 1.8622784614562988\n",
            "---------------------------\n",
            "Epoch 217\n",
            "loss: 1.8597379922866821\n",
            "---------------------------\n",
            "Epoch 218\n",
            "loss: 1.8747426271438599\n",
            "---------------------------\n",
            "Epoch 219\n",
            "loss: 1.8773788213729858\n",
            "---------------------------\n",
            "Epoch 220\n",
            "loss: 1.8607268333435059\n",
            "---------------------------\n",
            "Epoch 221\n",
            "loss: 1.8709582090377808\n",
            "---------------------------\n",
            "Epoch 222\n",
            "loss: 1.8791334629058838\n",
            "---------------------------\n",
            "Epoch 223\n",
            "loss: 1.880211591720581\n",
            "---------------------------\n",
            "Epoch 224\n",
            "loss: 1.854203462600708\n",
            "---------------------------\n",
            "Epoch 225\n",
            "loss: 1.849100112915039\n",
            "---------------------------\n",
            "Epoch 226\n",
            "loss: 1.8546768426895142\n",
            "---------------------------\n",
            "Epoch 227\n",
            "loss: 1.850814938545227\n",
            "---------------------------\n",
            "Epoch 228\n",
            "loss: 1.8503528833389282\n",
            "---------------------------\n",
            "Epoch 229\n",
            "loss: 1.858120322227478\n",
            "---------------------------\n",
            "Epoch 230\n",
            "loss: 1.8525502681732178\n",
            "---------------------------\n",
            "Epoch 231\n",
            "loss: 1.857374906539917\n",
            "---------------------------\n",
            "Epoch 232\n",
            "loss: 1.864249587059021\n",
            "---------------------------\n",
            "Epoch 233\n",
            "loss: 1.858080506324768\n",
            "---------------------------\n",
            "Epoch 234\n",
            "loss: 1.8657914400100708\n",
            "---------------------------\n",
            "Epoch 235\n",
            "loss: 1.8630589246749878\n",
            "---------------------------\n",
            "Epoch 236\n",
            "loss: 1.86049222946167\n",
            "---------------------------\n",
            "Epoch 237\n",
            "loss: 1.841078281402588\n",
            "---------------------------\n",
            "Epoch 238\n",
            "loss: 1.8441822528839111\n",
            "---------------------------\n",
            "Epoch 239\n",
            "loss: 1.8500615358352661\n",
            "---------------------------\n",
            "Epoch 240\n",
            "loss: 1.850907802581787\n",
            "---------------------------\n",
            "Epoch 241\n",
            "loss: 1.847232699394226\n",
            "---------------------------\n",
            "Epoch 242\n",
            "loss: 1.8523355722427368\n",
            "---------------------------\n",
            "Epoch 243\n",
            "loss: 1.8522981405258179\n",
            "---------------------------\n",
            "Epoch 244\n",
            "loss: 1.8574223518371582\n",
            "---------------------------\n",
            "Epoch 245\n",
            "loss: 1.8394054174423218\n",
            "---------------------------\n",
            "Epoch 246\n",
            "loss: 1.8506063222885132\n",
            "---------------------------\n",
            "Epoch 247\n",
            "loss: 1.8480746746063232\n",
            "---------------------------\n",
            "Epoch 248\n",
            "loss: 1.8376061916351318\n",
            "---------------------------\n",
            "Epoch 249\n",
            "loss: 1.8503271341323853\n",
            "---------------------------\n",
            "Epoch 250\n",
            "loss: 1.848509430885315\n",
            "---------------------------\n",
            "Epoch 251\n",
            "loss: 1.8480651378631592\n",
            "---------------------------\n",
            "Epoch 252\n",
            "loss: 1.853228211402893\n",
            "---------------------------\n",
            "Epoch 253\n",
            "loss: 1.8355693817138672\n",
            "---------------------------\n",
            "Epoch 254\n",
            "loss: 1.8413796424865723\n",
            "---------------------------\n",
            "Epoch 255\n",
            "loss: 1.8415135145187378\n",
            "---------------------------\n",
            "Epoch 256\n",
            "loss: 1.835968255996704\n",
            "---------------------------\n",
            "Epoch 257\n",
            "loss: 1.837205410003662\n",
            "---------------------------\n",
            "Epoch 258\n",
            "loss: 1.8319611549377441\n",
            "---------------------------\n",
            "Epoch 259\n",
            "loss: 1.8484278917312622\n",
            "---------------------------\n",
            "Epoch 260\n",
            "loss: 1.8367397785186768\n",
            "---------------------------\n",
            "Epoch 261\n",
            "loss: 1.8378348350524902\n",
            "---------------------------\n",
            "Epoch 262\n",
            "loss: 1.844102144241333\n",
            "---------------------------\n",
            "Epoch 263\n",
            "loss: 1.828572154045105\n",
            "---------------------------\n",
            "Epoch 264\n",
            "loss: 1.835551142692566\n",
            "---------------------------\n",
            "Epoch 265\n",
            "loss: 1.8355154991149902\n",
            "---------------------------\n",
            "Epoch 266\n",
            "loss: 1.8262050151824951\n",
            "---------------------------\n",
            "Epoch 267\n",
            "loss: 1.8301620483398438\n",
            "---------------------------\n",
            "Epoch 268\n",
            "loss: 1.829082727432251\n",
            "---------------------------\n",
            "Epoch 269\n",
            "loss: 1.820577621459961\n",
            "---------------------------\n",
            "Epoch 270\n",
            "loss: 1.831712007522583\n",
            "---------------------------\n",
            "Epoch 271\n",
            "loss: 1.8491113185882568\n",
            "---------------------------\n",
            "Epoch 272\n",
            "loss: 1.8268636465072632\n",
            "---------------------------\n",
            "Epoch 273\n",
            "loss: 1.830626130104065\n",
            "---------------------------\n",
            "Epoch 274\n",
            "loss: 1.8263708353042603\n",
            "---------------------------\n",
            "Epoch 275\n",
            "loss: 1.8226218223571777\n",
            "---------------------------\n",
            "Epoch 276\n",
            "loss: 1.826130747795105\n",
            "---------------------------\n",
            "Epoch 277\n",
            "loss: 1.828473448753357\n",
            "---------------------------\n",
            "Epoch 278\n",
            "loss: 1.8244708776474\n",
            "---------------------------\n",
            "Epoch 279\n",
            "loss: 1.8330515623092651\n",
            "---------------------------\n",
            "Epoch 280\n",
            "loss: 1.8299363851547241\n",
            "---------------------------\n",
            "Epoch 281\n",
            "loss: 1.8388782739639282\n",
            "---------------------------\n",
            "Epoch 282\n",
            "loss: 1.8292818069458008\n",
            "---------------------------\n",
            "Epoch 283\n",
            "loss: 1.8280706405639648\n",
            "---------------------------\n",
            "Epoch 284\n",
            "loss: 1.8583577871322632\n",
            "---------------------------\n",
            "Epoch 285\n",
            "loss: 1.8394922018051147\n",
            "---------------------------\n",
            "Epoch 286\n",
            "loss: 1.8588063716888428\n",
            "---------------------------\n",
            "Epoch 287\n",
            "loss: 1.8304804563522339\n",
            "---------------------------\n",
            "Epoch 288\n",
            "loss: 1.850238561630249\n",
            "---------------------------\n",
            "Epoch 289\n",
            "loss: 1.8317278623580933\n",
            "---------------------------\n",
            "Epoch 290\n",
            "loss: 1.8250212669372559\n",
            "---------------------------\n",
            "Epoch 291\n",
            "loss: 1.8083620071411133\n",
            "---------------------------\n",
            "Epoch 292\n",
            "loss: 1.818810224533081\n",
            "---------------------------\n",
            "Epoch 293\n",
            "loss: 1.8080756664276123\n",
            "---------------------------\n",
            "Epoch 294\n",
            "loss: 1.803898572921753\n",
            "---------------------------\n",
            "Epoch 295\n",
            "loss: 1.827154278755188\n",
            "---------------------------\n",
            "Epoch 296\n",
            "loss: 1.826931118965149\n",
            "---------------------------\n",
            "Epoch 297\n",
            "loss: 1.8197928667068481\n",
            "---------------------------\n",
            "Epoch 298\n",
            "loss: 1.8149877786636353\n",
            "---------------------------\n",
            "Epoch 299\n",
            "loss: 1.8054265975952148\n",
            "---------------------------\n",
            "Epoch 300\n",
            "loss: 1.8075940608978271\n",
            "---------------------------\n",
            "Epoch 301\n",
            "loss: 1.8107452392578125\n",
            "---------------------------\n",
            "Epoch 302\n",
            "loss: 1.8051637411117554\n",
            "---------------------------\n",
            "Epoch 303\n",
            "loss: 1.801496148109436\n",
            "---------------------------\n",
            "Epoch 304\n",
            "loss: 1.8149117231369019\n",
            "---------------------------\n",
            "Epoch 305\n",
            "loss: 1.8091294765472412\n",
            "---------------------------\n",
            "Epoch 306\n",
            "loss: 1.7995306253433228\n",
            "---------------------------\n",
            "Epoch 307\n",
            "loss: 1.8255119323730469\n",
            "---------------------------\n",
            "Epoch 308\n",
            "loss: 1.8327058553695679\n",
            "---------------------------\n",
            "Epoch 309\n",
            "loss: 1.83925199508667\n",
            "---------------------------\n",
            "Epoch 310\n",
            "loss: 1.826570749282837\n",
            "---------------------------\n",
            "Epoch 311\n",
            "loss: 1.8098551034927368\n",
            "---------------------------\n",
            "Epoch 312\n",
            "loss: 1.8295601606369019\n",
            "---------------------------\n",
            "Epoch 313\n",
            "loss: 1.826806902885437\n",
            "---------------------------\n",
            "Epoch 314\n",
            "loss: 1.7966604232788086\n",
            "---------------------------\n",
            "Epoch 315\n",
            "loss: 1.7989825010299683\n",
            "---------------------------\n",
            "Epoch 316\n",
            "loss: 1.8153518438339233\n",
            "---------------------------\n",
            "Epoch 317\n",
            "loss: 1.8119361400604248\n",
            "---------------------------\n",
            "Epoch 318\n",
            "loss: 1.8028686046600342\n",
            "---------------------------\n",
            "Epoch 319\n",
            "loss: 1.7941011190414429\n",
            "---------------------------\n",
            "Epoch 320\n",
            "loss: 1.803027868270874\n",
            "---------------------------\n",
            "Epoch 321\n",
            "loss: 1.799513578414917\n",
            "---------------------------\n",
            "Epoch 322\n",
            "loss: 1.7929097414016724\n",
            "---------------------------\n",
            "Epoch 323\n",
            "loss: 1.7944891452789307\n",
            "---------------------------\n",
            "Epoch 324\n",
            "loss: 1.7885291576385498\n",
            "---------------------------\n",
            "Epoch 325\n",
            "loss: 1.7841304540634155\n",
            "---------------------------\n",
            "Epoch 326\n",
            "loss: 1.7926216125488281\n",
            "---------------------------\n",
            "Epoch 327\n",
            "loss: 1.8034768104553223\n",
            "---------------------------\n",
            "Epoch 328\n",
            "loss: 1.8005317449569702\n",
            "---------------------------\n",
            "Epoch 329\n",
            "loss: 1.7988381385803223\n",
            "---------------------------\n",
            "Epoch 330\n",
            "loss: 1.7924774885177612\n",
            "---------------------------\n",
            "Epoch 331\n",
            "loss: 1.8021763563156128\n",
            "---------------------------\n",
            "Epoch 332\n",
            "loss: 1.7927567958831787\n",
            "---------------------------\n",
            "Epoch 333\n",
            "loss: 1.7859636545181274\n",
            "---------------------------\n",
            "Epoch 334\n",
            "loss: 1.7894562482833862\n",
            "---------------------------\n",
            "Epoch 335\n",
            "loss: 1.8025293350219727\n",
            "---------------------------\n",
            "Epoch 336\n",
            "loss: 1.783376932144165\n",
            "---------------------------\n",
            "Epoch 337\n",
            "loss: 1.8039230108261108\n",
            "---------------------------\n",
            "Epoch 338\n",
            "loss: 1.81110680103302\n",
            "---------------------------\n",
            "Epoch 339\n",
            "loss: 1.786649465560913\n",
            "---------------------------\n",
            "Epoch 340\n",
            "loss: 1.8103713989257812\n",
            "---------------------------\n",
            "Epoch 341\n",
            "loss: 1.7863517999649048\n",
            "---------------------------\n",
            "Epoch 342\n",
            "loss: 1.7836246490478516\n",
            "---------------------------\n",
            "Epoch 343\n",
            "loss: 1.776552438735962\n",
            "---------------------------\n",
            "Epoch 344\n",
            "loss: 1.7720530033111572\n",
            "---------------------------\n",
            "Epoch 345\n",
            "loss: 1.7811391353607178\n",
            "---------------------------\n",
            "Epoch 346\n",
            "loss: 1.775620460510254\n",
            "---------------------------\n",
            "Epoch 347\n",
            "loss: 1.7752257585525513\n",
            "---------------------------\n",
            "Epoch 348\n",
            "loss: 1.8188844919204712\n",
            "---------------------------\n",
            "Epoch 349\n",
            "loss: 1.7961196899414062\n",
            "---------------------------\n",
            "Epoch 350\n",
            "loss: 1.8016340732574463\n",
            "---------------------------\n",
            "Epoch 351\n",
            "loss: 1.8212378025054932\n",
            "---------------------------\n",
            "Epoch 352\n",
            "loss: 1.8202944993972778\n",
            "---------------------------\n",
            "Epoch 353\n",
            "loss: 1.798056960105896\n",
            "---------------------------\n",
            "Epoch 354\n",
            "loss: 1.7827330827713013\n",
            "---------------------------\n",
            "Epoch 355\n",
            "loss: 1.7847644090652466\n",
            "---------------------------\n",
            "Epoch 356\n",
            "loss: 1.7833592891693115\n",
            "---------------------------\n",
            "Epoch 357\n",
            "loss: 1.7805067300796509\n",
            "---------------------------\n",
            "Epoch 358\n",
            "loss: 1.782097339630127\n",
            "---------------------------\n",
            "Epoch 359\n",
            "loss: 1.7824290990829468\n",
            "---------------------------\n",
            "Epoch 360\n",
            "loss: 1.7806068658828735\n",
            "---------------------------\n",
            "Epoch 361\n",
            "loss: 1.7803853750228882\n",
            "---------------------------\n",
            "Epoch 362\n",
            "loss: 1.7702381610870361\n",
            "---------------------------\n",
            "Epoch 363\n",
            "loss: 1.7688461542129517\n",
            "---------------------------\n",
            "Epoch 364\n",
            "loss: 1.7717410326004028\n",
            "---------------------------\n",
            "Epoch 365\n",
            "loss: 1.7696183919906616\n",
            "---------------------------\n",
            "Epoch 366\n",
            "loss: 1.7665724754333496\n",
            "---------------------------\n",
            "Epoch 367\n",
            "loss: 1.7719268798828125\n",
            "---------------------------\n",
            "Epoch 368\n",
            "loss: 1.7760339975357056\n",
            "---------------------------\n",
            "Epoch 369\n",
            "loss: 1.7705738544464111\n",
            "---------------------------\n",
            "Epoch 370\n",
            "loss: 1.7768354415893555\n",
            "---------------------------\n",
            "Epoch 371\n",
            "loss: 1.7882051467895508\n",
            "---------------------------\n",
            "Epoch 372\n",
            "loss: 1.7826077938079834\n",
            "---------------------------\n",
            "Epoch 373\n",
            "loss: 1.7959182262420654\n",
            "---------------------------\n",
            "Epoch 374\n",
            "loss: 1.7719826698303223\n",
            "---------------------------\n",
            "Epoch 375\n",
            "loss: 1.7792119979858398\n",
            "---------------------------\n",
            "Epoch 376\n",
            "loss: 1.7687351703643799\n",
            "---------------------------\n",
            "Epoch 377\n",
            "loss: 1.7647191286087036\n",
            "---------------------------\n",
            "Epoch 378\n",
            "loss: 1.7592575550079346\n",
            "---------------------------\n",
            "Epoch 379\n",
            "loss: 1.7638548612594604\n",
            "---------------------------\n",
            "Epoch 380\n",
            "loss: 1.763814926147461\n",
            "---------------------------\n",
            "Epoch 381\n",
            "loss: 1.7615423202514648\n",
            "---------------------------\n",
            "Epoch 382\n",
            "loss: 1.7715526819229126\n",
            "---------------------------\n",
            "Epoch 383\n",
            "loss: 1.7995610237121582\n",
            "---------------------------\n",
            "Epoch 384\n",
            "loss: 1.7850923538208008\n",
            "---------------------------\n",
            "Epoch 385\n",
            "loss: 1.7735992670059204\n",
            "---------------------------\n",
            "Epoch 386\n",
            "loss: 1.7916126251220703\n",
            "---------------------------\n",
            "Epoch 387\n",
            "loss: 1.7755217552185059\n",
            "---------------------------\n",
            "Epoch 388\n",
            "loss: 1.7616642713546753\n",
            "---------------------------\n",
            "Epoch 389\n",
            "loss: 1.761584758758545\n",
            "---------------------------\n",
            "Epoch 390\n",
            "loss: 1.7669703960418701\n",
            "---------------------------\n",
            "Epoch 391\n",
            "loss: 1.7651917934417725\n",
            "---------------------------\n",
            "Epoch 392\n",
            "loss: 1.7672111988067627\n",
            "---------------------------\n",
            "Epoch 393\n",
            "loss: 1.7819346189498901\n",
            "---------------------------\n",
            "Epoch 394\n",
            "loss: 1.7801584005355835\n",
            "---------------------------\n",
            "Epoch 395\n",
            "loss: 1.7806222438812256\n",
            "---------------------------\n",
            "Epoch 396\n",
            "loss: 1.7824513912200928\n",
            "---------------------------\n",
            "Epoch 397\n",
            "loss: 1.76924729347229\n",
            "---------------------------\n",
            "Epoch 398\n",
            "loss: 1.772110939025879\n",
            "---------------------------\n",
            "Epoch 399\n",
            "loss: 1.7991259098052979\n",
            "---------------------------\n",
            "Epoch 400\n",
            "loss: 1.7933870553970337\n",
            "---------------------------\n",
            "Epoch 401\n",
            "loss: 1.7835822105407715\n",
            "---------------------------\n",
            "Epoch 402\n",
            "loss: 1.7859784364700317\n",
            "---------------------------\n",
            "Epoch 403\n",
            "loss: 1.7704410552978516\n",
            "---------------------------\n",
            "Epoch 404\n",
            "loss: 1.7625499963760376\n",
            "---------------------------\n",
            "Epoch 405\n",
            "loss: 1.7676624059677124\n",
            "---------------------------\n",
            "Epoch 406\n",
            "loss: 1.7882192134857178\n",
            "---------------------------\n",
            "Epoch 407\n",
            "loss: 1.7646739482879639\n",
            "---------------------------\n",
            "Epoch 408\n",
            "loss: 1.7544469833374023\n",
            "---------------------------\n",
            "Epoch 409\n",
            "loss: 1.7535728216171265\n",
            "---------------------------\n",
            "Epoch 410\n",
            "loss: 1.754500150680542\n",
            "---------------------------\n",
            "Epoch 411\n",
            "loss: 1.7580734491348267\n",
            "---------------------------\n",
            "Epoch 412\n",
            "loss: 1.7583796977996826\n",
            "---------------------------\n",
            "Epoch 413\n",
            "loss: 1.7684059143066406\n",
            "---------------------------\n",
            "Epoch 414\n",
            "loss: 1.7547085285186768\n",
            "---------------------------\n",
            "Epoch 415\n",
            "loss: 1.7521849870681763\n",
            "---------------------------\n",
            "Epoch 416\n",
            "loss: 1.7499173879623413\n",
            "---------------------------\n",
            "Epoch 417\n",
            "loss: 1.7551676034927368\n",
            "---------------------------\n",
            "Epoch 418\n",
            "loss: 1.7596371173858643\n",
            "---------------------------\n",
            "Epoch 419\n",
            "loss: 1.7639119625091553\n",
            "---------------------------\n",
            "Epoch 420\n",
            "loss: 1.7793747186660767\n",
            "---------------------------\n",
            "Epoch 421\n",
            "loss: 1.7611550092697144\n",
            "---------------------------\n",
            "Epoch 422\n",
            "loss: 1.7515991926193237\n",
            "---------------------------\n",
            "Epoch 423\n",
            "loss: 1.7526599168777466\n",
            "---------------------------\n",
            "Epoch 424\n",
            "loss: 1.7675716876983643\n",
            "---------------------------\n",
            "Epoch 425\n",
            "loss: 1.7545714378356934\n",
            "---------------------------\n",
            "Epoch 426\n",
            "loss: 1.753238558769226\n",
            "---------------------------\n",
            "Epoch 427\n",
            "loss: 1.746935248374939\n",
            "---------------------------\n",
            "Epoch 428\n",
            "loss: 1.7554104328155518\n",
            "---------------------------\n",
            "Epoch 429\n",
            "loss: 1.7546162605285645\n",
            "---------------------------\n",
            "Epoch 430\n",
            "loss: 1.754319429397583\n",
            "---------------------------\n",
            "Epoch 431\n",
            "loss: 1.755325198173523\n",
            "---------------------------\n",
            "Epoch 432\n",
            "loss: 1.7521435022354126\n",
            "---------------------------\n",
            "Epoch 433\n",
            "loss: 1.7850390672683716\n",
            "---------------------------\n",
            "Epoch 434\n",
            "loss: 1.7628289461135864\n",
            "---------------------------\n",
            "Epoch 435\n",
            "loss: 1.7505683898925781\n",
            "---------------------------\n",
            "Epoch 436\n",
            "loss: 1.7559456825256348\n",
            "---------------------------\n",
            "Epoch 437\n",
            "loss: 1.7512327432632446\n",
            "---------------------------\n",
            "Epoch 438\n",
            "loss: 1.764680027961731\n",
            "---------------------------\n",
            "Epoch 439\n",
            "loss: 1.7492583990097046\n",
            "---------------------------\n",
            "Epoch 440\n",
            "loss: 1.7519195079803467\n",
            "---------------------------\n",
            "Epoch 441\n",
            "loss: 1.7731140851974487\n",
            "---------------------------\n",
            "Epoch 442\n",
            "loss: 1.7711421251296997\n",
            "---------------------------\n",
            "Epoch 443\n",
            "loss: 1.750939130783081\n",
            "---------------------------\n",
            "Epoch 444\n",
            "loss: 1.7455527782440186\n",
            "---------------------------\n",
            "Epoch 445\n",
            "loss: 1.7465635538101196\n",
            "---------------------------\n",
            "Epoch 446\n",
            "loss: 1.7446131706237793\n",
            "---------------------------\n",
            "Epoch 447\n",
            "loss: 1.7478687763214111\n",
            "---------------------------\n",
            "Epoch 448\n",
            "loss: 1.751176118850708\n",
            "---------------------------\n",
            "Epoch 449\n",
            "loss: 1.7445039749145508\n",
            "---------------------------\n",
            "Epoch 450\n",
            "loss: 1.760282039642334\n",
            "---------------------------\n",
            "Epoch 451\n",
            "loss: 1.7497365474700928\n",
            "---------------------------\n",
            "Epoch 452\n",
            "loss: 1.7476311922073364\n",
            "---------------------------\n",
            "Epoch 453\n",
            "loss: 1.7687665224075317\n",
            "---------------------------\n",
            "Epoch 454\n",
            "loss: 1.8029568195343018\n",
            "---------------------------\n",
            "Epoch 455\n",
            "loss: 1.7622220516204834\n",
            "---------------------------\n",
            "Epoch 456\n",
            "loss: 1.7519173622131348\n",
            "---------------------------\n",
            "Epoch 457\n",
            "loss: 1.7485202550888062\n",
            "---------------------------\n",
            "Epoch 458\n",
            "loss: 1.7411534786224365\n",
            "---------------------------\n",
            "Epoch 459\n",
            "loss: 1.7450964450836182\n",
            "---------------------------\n",
            "Epoch 460\n",
            "loss: 1.7486521005630493\n",
            "---------------------------\n",
            "Epoch 461\n",
            "loss: 1.7413359880447388\n",
            "---------------------------\n",
            "Epoch 462\n",
            "loss: 1.7434176206588745\n",
            "---------------------------\n",
            "Epoch 463\n",
            "loss: 1.7421071529388428\n",
            "---------------------------\n",
            "Epoch 464\n",
            "loss: 1.7548649311065674\n",
            "---------------------------\n",
            "Epoch 465\n",
            "loss: 1.7485324144363403\n",
            "---------------------------\n",
            "Epoch 466\n",
            "loss: 1.7721328735351562\n",
            "---------------------------\n",
            "Epoch 467\n",
            "loss: 1.7534552812576294\n",
            "---------------------------\n",
            "Epoch 468\n",
            "loss: 1.7439711093902588\n",
            "---------------------------\n",
            "Epoch 469\n",
            "loss: 1.7359051704406738\n",
            "---------------------------\n",
            "Epoch 470\n",
            "loss: 1.7535704374313354\n",
            "---------------------------\n",
            "Epoch 471\n",
            "loss: 1.7423739433288574\n",
            "---------------------------\n",
            "Epoch 472\n",
            "loss: 1.740709900856018\n",
            "---------------------------\n",
            "Epoch 473\n",
            "loss: 1.7392256259918213\n",
            "---------------------------\n",
            "Epoch 474\n",
            "loss: 1.7360916137695312\n",
            "---------------------------\n",
            "Epoch 475\n",
            "loss: 1.739583134651184\n",
            "---------------------------\n",
            "Epoch 476\n",
            "loss: 1.7370458841323853\n",
            "---------------------------\n",
            "Epoch 477\n",
            "loss: 1.7338833808898926\n",
            "---------------------------\n",
            "Epoch 478\n",
            "loss: 1.7454793453216553\n",
            "---------------------------\n",
            "Epoch 479\n",
            "loss: 1.7662800550460815\n",
            "---------------------------\n",
            "Epoch 480\n",
            "loss: 1.7464251518249512\n",
            "---------------------------\n",
            "Epoch 481\n",
            "loss: 1.7381062507629395\n",
            "---------------------------\n",
            "Epoch 482\n",
            "loss: 1.7588386535644531\n",
            "---------------------------\n",
            "Epoch 483\n",
            "loss: 1.7419381141662598\n",
            "---------------------------\n",
            "Epoch 484\n",
            "loss: 1.7323499917984009\n",
            "---------------------------\n",
            "Epoch 485\n",
            "loss: 1.738460898399353\n",
            "---------------------------\n",
            "Epoch 486\n",
            "loss: 1.7506897449493408\n",
            "---------------------------\n",
            "Epoch 487\n",
            "loss: 1.7480577230453491\n",
            "---------------------------\n",
            "Epoch 488\n",
            "loss: 1.737757682800293\n",
            "---------------------------\n",
            "Epoch 489\n",
            "loss: 1.7411434650421143\n",
            "---------------------------\n",
            "Epoch 490\n",
            "loss: 1.7301864624023438\n",
            "---------------------------\n",
            "Epoch 491\n",
            "loss: 1.741068720817566\n",
            "---------------------------\n",
            "Epoch 492\n",
            "loss: 1.7536840438842773\n",
            "---------------------------\n",
            "Epoch 493\n",
            "loss: 1.7338347434997559\n",
            "---------------------------\n",
            "Epoch 494\n",
            "loss: 1.7557311058044434\n",
            "---------------------------\n",
            "Epoch 495\n",
            "loss: 1.7856037616729736\n",
            "---------------------------\n",
            "Epoch 496\n",
            "loss: 1.7455511093139648\n",
            "---------------------------\n",
            "Epoch 497\n",
            "loss: 1.7488324642181396\n",
            "---------------------------\n",
            "Epoch 498\n",
            "loss: 1.748245358467102\n",
            "---------------------------\n",
            "Epoch 499\n",
            "loss: 1.7317261695861816\n",
            "---------------------------\n",
            "Epoch 500\n",
            "loss: 1.741916298866272\n",
            "---------------------------\n",
            "Finished training\n",
            "Trained feed forward net saved at feedforwardnet_filter_FINAL_Sharpen_Gamma_NotNormalized_500_trial_1.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#from urbansounddataset import UrbanSoundDataset\n",
        "#from cnn import CNNNetwork\n",
        "\n",
        "\n",
        "BATCH_SIZE = 1024\n",
        "EPOCHS = 500\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "ANNOTATIONS_FILE = \"/content/UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
        "AUDIO_DIR = \"/content/UrbanSound8K/audio\"\n",
        "SAMPLE_RATE = 22050\n",
        "NUM_SAMPLES = 22050\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "def create_data_loader(train_data, batch_size):\n",
        "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "    return train_dataloader\n",
        "\n",
        "\n",
        "def train_single_epoch(model, data_loader, loss_fn, optimiser, device):\n",
        "    for input, target in data_loader:\n",
        "        input, target = input.to(device), target.to(device)\n",
        "\n",
        "        # calculate loss\n",
        "        prediction = model(input)\n",
        "        loss = loss_fn(prediction, target)\n",
        "\n",
        "        # backpropagate error and update weights\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "    print(f\"loss: {loss.item()}\")\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "\n",
        "def train(model, data_loader, loss_fn, optimiser, device, epochs):\n",
        "    for i in range(epochs):\n",
        "        print(f\"Epoch {i+1}\")\n",
        "        train_single_epoch(model, data_loader, loss_fn, optimiser, device)\n",
        "        print(\"---------------------------\")\n",
        "    print(\"Finished training\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "    print(f\"Using {device}\")\n",
        "\n",
        "    # instantiating our dataset object and create data loader\n",
        "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=SAMPLE_RATE,\n",
        "        n_fft=1024,\n",
        "        hop_length=512,\n",
        "        n_mels=64\n",
        "    )\n",
        "\n",
        "    train_dataloader = create_data_loader(train_set, BATCH_SIZE)\n",
        "\n",
        "    # construct model and assign it to device\n",
        "    cnn = CNN_Filter_Network().to(device)\n",
        "    print(cnn)\n",
        "\n",
        "    # initialise loss funtion + optimiser\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimiser = torch.optim.Adam(cnn.parameters(),\n",
        "                                 lr=LEARNING_RATE)\n",
        "\n",
        "    # train model\n",
        "    train(cnn, train_dataloader, loss_fn, optimiser, device, EPOCHS)\n",
        "\n",
        "    # save model\n",
        "    torch.save(cnn.state_dict(), \"feedforwardnet_filter_FINAL_Sharpen_Gamma_NotNormalized_500_trial_1.pth\")\n",
        "    print(\"Trained feed forward net saved at feedforwardnet_filter_FINAL_Sharpen_Gamma_NotNormalized_500_trial_1.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uVQ7u44MjSeB",
        "outputId": "a316e14e-013f-4bdf-f75f-4289a42c0fd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: 'air_conditioner', expected: 'air_conditioner'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "#from cnn import CNNNetwork\n",
        "#from urbansounddataset import UrbanSoundDataset\n",
        "#from train import AUDIO_DIR, ANNOTATIONS_FILE, SAMPLE_RATE, NUM_SAMPLES\n",
        "\n",
        "\n",
        "class_mapping = [\n",
        "    \"air_conditioner\",\n",
        "    \"car_horn\",\n",
        "    \"children_playing\",\n",
        "    \"dog_bark\",\n",
        "    \"drilling\",\n",
        "    \"engine_idling\",\n",
        "    \"gun_shot\",\n",
        "    \"jackhammer\",\n",
        "    \"siren\",\n",
        "    \"street_music\"\n",
        "]\n",
        "\n",
        "\n",
        "def predict(model, input, target, class_mapping):\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(input)\n",
        "        # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n",
        "        predicted_index = predictions[0].argmax(0)\n",
        "        predicted = class_mapping[predicted_index]\n",
        "        expected = class_mapping[target]\n",
        "    return predicted, expected\n",
        "\n",
        "\n",
        "# load back the model\n",
        "cnn = CNN_Filter_Network()\n",
        "state_dict = torch.load(\"feedforwardnet_filter_FINAL_Sharpen_Gamma_NotNormalized_500_trial_1.pth\")\n",
        "for name, weights in state_dict.items():\n",
        "    if 'gamma_scale' in name:\n",
        "        state_dict[name] = weights.unsqueeze(-1)\n",
        "    if 'sharpness_scale' in name:\n",
        "        state_dict[name] = weights.unsqueeze(-1)\n",
        "cnn.load_state_dict(state_dict)\n",
        "\n",
        "# load urban sound dataset dataset\n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=SAMPLE_RATE,\n",
        "    n_fft=1024,\n",
        "    hop_length=512,\n",
        "    n_mels=64\n",
        ")\n",
        "\n",
        "usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n",
        "                        AUDIO_DIR,\n",
        "                        mel_spectrogram,\n",
        "                        SAMPLE_RATE,\n",
        "                        NUM_SAMPLES,\n",
        "                        \"cpu\")\n",
        "\n",
        "\n",
        "# get a sample from the urban sound dataset for inference\n",
        "input, target = test_set[0][0], test_set[0][1] # [batch size, num_channels, fr, time]\n",
        "input.unsqueeze_(0)\n",
        "\n",
        "# make an inference\n",
        "predicted, expected = predict(cnn, input, target,\n",
        "                              class_mapping)\n",
        "print(f\"Predicted: '{predicted}', expected: '{expected}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PXgzcEvcvwq4"
      },
      "outputs": [],
      "source": [
        "sumRight = 0\n",
        "for i in range(1000):\n",
        "    input, target = train_set[i][0], train_set[i][1]\n",
        "    input.unsqueeze_(0)\n",
        "\n",
        "    # make an inference\n",
        "    predicted, expected = predict(cnn, input, target,\n",
        "                                  class_mapping)\n",
        "    if predicted == expected:\n",
        "        sumRight += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L1_uPVHovyDn",
        "outputId": "475cee55-59f7-49a8-fe66-a5ad661c19bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.735"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sumRight/1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DydVVfdRvzy_"
      },
      "outputs": [],
      "source": [
        "sumRight = 0\n",
        "for i in range(1000):\n",
        "    input, target = test_set[i][0], test_set[i][1]\n",
        "    input.unsqueeze_(0)\n",
        "\n",
        "    # make an inference\n",
        "    predicted, expected = predict(cnn, input, target,\n",
        "                                  class_mapping)\n",
        "    if predicted == expected:\n",
        "        sumRight += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jjPR3eS698p1",
        "outputId": "61fcc22f-1af0-4e7d-e54c-de0ab349743c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.623"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sumRight/1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xqFe3rsZ-Gpj",
        "outputId": "ee00d45f-4a03-4fa4-f2cd-ef8110ab262b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(loss_list)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HYNsTumCRX_p"
      },
      "outputs": [],
      "source": [
        "!cp feedforwardnet_filter_FINAL_Sharpen_Gamma_NotNormalized_500_trial_1.pth \"/content/drive/My Drive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my2NIfDnveeZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AudioFilterNetwork_FINAL_Sharpen_Gamma_NotNormalized_500_trial_1.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}